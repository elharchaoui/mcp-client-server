{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c10b768-f5b4-43bc-a785-99077422ce78",
   "metadata": {},
   "source": [
    "# Lesson 3: Chatbot Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4fedc-4b90-4754-9f2d-fd3cfa321a14",
   "metadata": {},
   "source": [
    "In this lesson, you will familiarize yourself with the chatbot example you will work on during this course. The example includes the tool definitions and execution, as well as the chatbot code. Make sure to interact with the chatbot at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed96ba-5ade-4af4-9096-406ce48d5cf2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6bd1d4-f652-45d1-9efa-155a2cc01713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f163a-87af-4e0c-87ed-1624c150c572",
   "metadata": {},
   "source": [
    "## Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549a7f46-74b3-4a1d-b084-055c99e3c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43905e-56f3-404c-a322-f038055e9b1c",
   "metadata": {},
   "source": [
    "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the `papers` directory. The tool does not download the papers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886633b8-ce67-4343-822d-cc3f98f953fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20ee17a-afe6-438a-95b1-6e87742c7fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/computers_ai_browser/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2503.16586v2',\n",
       " '1802.03707v1',\n",
       " '2111.01677v1',\n",
       " '2205.15686v2',\n",
       " '2009.03740v1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"computers ai browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb83565-69af-47f3-9ba3-a96965cff7df",
   "metadata": {},
   "source": [
    "The second tool looks for information about a specific paper across all topic directories inside the `papers` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9b1997-81cd-447d-9665-1cb72d93bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ebe0de7-8f07-4e08-a670-7b371fc3d2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"Big Help or Big Brother? Auditing Tracking, Profiling, and Personalization in Generative AI Assistants\",\n",
      "  \"authors\": [\n",
      "    \"Yash Vekaria\",\n",
      "    \"Aurelio Loris Canino\",\n",
      "    \"Jonathan Levitsky\",\n",
      "    \"Alex Ciechonski\",\n",
      "    \"Patricia Callejo\",\n",
      "    \"Anna Maria Mandalari\",\n",
      "    \"Zubair Shafiq\"\n",
      "  ],\n",
      "  \"summary\": \"Generative AI (GenAI) browser assistants integrate powerful capabilities of\\nGenAI in web browsers to provide rich experiences such as question answering,\\ncontent summarization, and agentic navigation. These assistants, available\\ntoday as browser extensions, can not only track detailed browsing activity such\\nas search and click data, but can also autonomously perform tasks such as\\nfilling forms, raising significant privacy concerns. It is crucial to\\nunderstand the design and operation of GenAI browser extensions, including how\\nthey collect, store, process, and share user data. To this end, we study their\\nability to profile users and personalize their responses based on explicit or\\ninferred demographic attributes and interests of users. We perform network\\ntraffic analysis and use a novel prompting framework to audit tracking,\\nprofiling, and personalization by the ten most popular GenAI browser assistant\\nextensions. We find that instead of relying on local in-browser models, these\\nassistants largely depend on server-side APIs, which can be auto-invoked\\nwithout explicit user interaction. When invoked, they collect and share webpage\\ncontent, often the full HTML DOM and sometimes even the user's form inputs,\\nwith their first-party servers. Some assistants also share identifiers and user\\nprompts with third-party trackers such as Google Analytics. The collection and\\nsharing continues even if a webpage contains sensitive information such as\\nhealth or personal information such as name or SSN entered in a web form. We\\nfind that several GenAI browser assistants infer demographic attributes such as\\nage, gender, income, and interests and use this profile--which carries across\\nbrowsing contexts--to personalize responses. In summary, our work shows that\\nGenAI browser assistants can and do collect personal and sensitive information\\nfor profiling and personalization with little to no safeguards.\",\n",
      "  \"pdf_url\": \"http://arxiv.org/pdf/2503.16586v2\",\n",
      "  \"published\": \"2025-03-20\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(extract_info('2503.16586v2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea3013-e690-4bc8-8622-27b4d42d61e4",
   "metadata": {},
   "source": [
    "## Tool Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d2260-452d-472a-b56e-326479cb18c9",
   "metadata": {},
   "source": [
    "Here are the schema of each tool which you will provide to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5bdea5f-e93a-4018-8c13-00d5ee10c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec668d24-1559-41b7-bc8a-e2dca77dfaf2",
   "metadata": {},
   "source": [
    "## Tool Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728c1ec-36b1-48b4-9f85-622464ac79f4",
   "metadata": {},
   "source": [
    "This code handles tool mapping and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c90790c0-efc4-4068-9c00-d2592d80bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8fc4d3-58ac-482c-8bbd-bccd6ef9fc31",
   "metadata": {},
   "source": [
    "## Chatbot Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba0fad-b0e4-4415-a431-341e9ca85087",
   "metadata": {},
   "source": [
    "The chatbot handles the user's queries one by one, but it does not persist memory across the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe662400-8506-464e-a3da-75a3d8848bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fec259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# How AI Might Transform Internet Operations\n",
      "\n",
      "AI is increasingly influencing how the internet functions in several key ways:\n",
      "\n",
      "## Current and Emerging Roles\n",
      "\n",
      "- **Content Moderation**: AI systems filter harmful content at scale across platforms\n",
      "- **Traffic Management**: AI optimizes network routing and bandwidth allocation\n",
      "- **Personalization**: AI powers recommendation systems and tailored user experiences\n",
      "- **Cybersecurity**: AI detects and responds to threats in real-time\n",
      "\n",
      "## Future Possibilities\n",
      "\n",
      "- **Autonomous Infrastructure**: Self-healing networks that predict and prevent outages\n",
      "- **Advanced Search**: Moving beyond keywords to understanding context and intent\n",
      "- **Decentralized Governance**: AI could help manage distributed systems and protocols\n",
      "- **Intelligent Interfaces**: More natural interaction through conversational AI\n",
      "\n",
      "However, this transformation raises important considerations around algorithmic bias, privacy, accountability, and human oversight. The most likely future involves AI handling more operational aspects while humans maintain strategic control and ethical guidance.\n"
     ]
    }
   ],
   "source": [
    "query = \"how ai will run the internet ?\"\n",
    "messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "response = client.messages.create(max_tokens = 2024,\n",
    "                                model = 'claude-3-7-sonnet-20250219', \n",
    "                                messages = messages)\n",
    "\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e6b5348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextBlock(citations=None, text='# How AI Might Transform Internet Operations\\n\\nAI is increasingly influencing how the internet functions in several key ways:\\n\\n## Current and Emerging Roles\\n\\n- **Content Moderation**: AI systems filter harmful content at scale across platforms\\n- **Traffic Management**: AI optimizes network routing and bandwidth allocation\\n- **Personalization**: AI powers recommendation systems and tailored user experiences\\n- **Cybersecurity**: AI detects and responds to threats in real-time\\n\\n## Future Possibilities\\n\\n- **Autonomous Infrastructure**: Self-healing networks that predict and prevent outages\\n- **Advanced Search**: Moving beyond keywords to understanding context and intent\\n- **Decentralized Governance**: AI could help manage distributed systems and protocols\\n- **Intelligent Interfaces**: More natural interaction through conversational AI\\n\\nHowever, this transformation raises important considerations around algorithmic bias, privacy, accountability, and human oversight. The most likely future involves AI handling more operational aspects while humans maintain strategic control and ethical guidance.', type='text')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7da15cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"diffusion models in NP problem solving\"\n",
    "messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "response = client.messages.create(max_tokens = 2024,\n",
    "                                model = 'claude-3-7-sonnet-20250219', \n",
    "                                tools = tools,\n",
    "                                messages = messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c4be6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextBlock(citations=None, text=\"I'll search for papers related to diffusion models in NP problem solving for you. Let me do that search now.\", type='text'),\n",
       " ToolUseBlock(id='toolu_01DWHTJTf5d3bwuGg54JLioh', input={'topic': 'diffusion models NP problem solving', 'max_results': 5}, name='search_papers', type='tool_use')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175586b4-acdf-4103-8039-134478a4f797",
   "metadata": {},
   "source": [
    "### Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12a896e0-3f56-417e-aa51-c61756048593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages)\n",
    "    \n",
    "    running = True\n",
    "    loop_counter = 1\n",
    "    while running:\n",
    "        assistant_content = []\n",
    "        print(f\"round {loop_counter}, content len {len(response.content)}\")\n",
    "        for content in response.content:\n",
    "            if content.type == 'text':\n",
    "                \n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "                \n",
    "                if len(response.content) == 1:\n",
    "                    running = False\n",
    "            \n",
    "            elif content.type == 'tool_use':\n",
    "                \n",
    "                assistant_content.append(content)\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                messages.append({\"role\": \"user\", \n",
    "                                  \"content\": [\n",
    "                                      {\n",
    "                                          \"type\": \"tool_result\",\n",
    "                                          \"tool_use_id\": tool_id,\n",
    "                                          \"content\": result\n",
    "                                      }\n",
    "                                  ]\n",
    "                                })\n",
    "                response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages) \n",
    "                \n",
    "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
    "                    print(response.content[0].text)\n",
    "                    running = False\n",
    "        loop_counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921ee7f-d2be-464b-ab7b-8db2a3c13ba9",
   "metadata": {},
   "source": [
    "### Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16979cdc-81e9-432b-ba7f-e810b52961e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaf254-f22a-4951-885e-1d21fbc41ff3",
   "metadata": {},
   "source": [
    "Feel free to interact with the chatbot. Here's an example query: \n",
    "\n",
    "- Search for 2 papers on \"LLM interpretability\"\n",
    "\n",
    "To access the `papers` folder: 1) click on the `File` option on the top menu of the notebook and 2) click on `Open` and then 3) click on `L3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39676f70-1c72-4da3-8363-da281bd5a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "round 1, content len 2\n",
      "I'd like to search for papers on arXiv that discuss generative AI as a tool for solving NP problems. Let me do that for you.\n",
      "Calling tool search_papers with args {'topic': 'generative AI NP problem solver'}\n",
      "Results are saved in: papers/generative_ai_np_problem_solver/papers_info.json\n",
      "round 2, content len 2\n",
      "I've found several papers that might be relevant to generative AI as an NP problem solver. Let me get more detailed information about each of these papers to better understand how they relate to your topic.\n",
      "Calling tool extract_info with args {'paper_id': '2502.03669v1'}\n",
      "round 3, content len 1\n",
      "Calling tool extract_info with args {'paper_id': '0804.4457v1'}\n",
      "round 4, content len 1\n",
      "Calling tool extract_info with args {'paper_id': '2504.06126v1'}\n",
      "round 5, content len 1\n",
      "Calling tool extract_info with args {'paper_id': '1011.5447v1'}\n",
      "round 6, content len 1\n",
      "Calling tool extract_info with args {'paper_id': '2309.03924v1'}\n",
      "Based on my search, I've found several relevant papers discussing how AI and generative approaches are being applied to solve NP problems. Here's a summary of what I found:\n",
      "\n",
      "## Generative AI and NP Problem Solving: Current Research\n",
      "\n",
      "1. **Comparing AI vs. Classical Methods for NP Problems** (2025)\n",
      "   - The paper \"Unrealized Expectations\" compares generative models and reinforcement learning approaches with classical algorithms for solving the Maximum Independent Set problem (an NP-hard problem).\n",
      "   - Interestingly, the researchers found that current AI-based methods often fail to outperform traditional classical solvers running on CPUs.\n",
      "   - Some AI methods like GFlowNets (generative flow networks) end up reasoning similarly to simple greedy approaches.\n",
      "\n",
      "2. **Quantum Computing for NP-Hard AI Problems** (2008)\n",
      "   - The paper on \"Image recognition with an adiabatic quantum computer\" discusses mapping NP-hard AI problems (specifically image recognition) to a form solvable by quantum computing hardware.\n",
      "   - This represents an interesting approach where quantum algorithms might provide advantages for NP-hard optimization problems.\n",
      "\n",
      "3. **Hybrid AI Approaches for Vehicle Routing** (2025)\n",
      "   - \"Accelerating Vehicle Routing via AI-Initialized Genetic Algorithms\" presents a hybrid approach where reinforcement learning is used to quickly generate initial solutions for the Vehicle Routing Problem (VRP).\n",
      "   - This approach combines generative AI (reinforcement learning) with genetic algorithms to solve NP-hard problems 10x faster than current solvers.\n",
      "\n",
      "4. **SAT and Integer Programming for NP Problems** (2010)\n",
      "   - \"Proof of Concept\" discusses using SAT and Integer Programming solvers for addressing NP problems.\n",
      "   - While not directly about generative AI, it's relevant as it shows traditional approaches to NP problem solving.\n",
      "\n",
      "5. **Machine Learning for Algorithm Selection** (2023)\n",
      "   - \"Automatic Algorithm Selection for Pseudo-Boolean Optimization\" uses machine learning techniques to predict which solver would be best for a given NP-hard problem instance.\n",
      "   - This meta-solver approach demonstrates significant improvements over using any single solver (like Gurobi).\n",
      "\n",
      "## Key Insights\n",
      "\n",
      "- There's an active area of research exploring generative AI and other AI methods for solving NP-hard problems, but the results are mixed.\n",
      "- Current research suggests that hybrid approaches (combining AI with traditional methods) may be more promising than pure AI approaches.\n",
      "- While generative AI shows promise, it hasn't yet consistently outperformed specialized classical algorithms for many NP problems.\n",
      "- The field is rapidly evolving, with papers from 2025 showing continued research interest in this area.\n",
      "\n",
      "Would you like me to search for additional papers or focus on a specific aspect of generative AI for NP problem solving?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df7890-4b4c-4ec9-b06f-abc8c4a290e8",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> 🚨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34ee2d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> 💻 &nbsp; <b> To Access the <code>requirements.txt</code> file or the <code>papers</code> folder: </b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em> and finally 3) click on <em>\"L3\"</em>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508916f3-8fa1-4e21-bfa7-081a810bc36c",
   "metadata": {},
   "source": [
    "In the next lessons, you will take out the tool definitions to wrap them in an MCP server. Then you will create an MCP client inside the chatbot to make the chatbot MCP compatible.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d207b-e07d-49ff-bb03-7954aa86c167",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Guide on how to implement tool use](https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview#how-to-implement-tool-use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e5135e-01c3-4632-9f83-a1e6dd811049",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "\n",
    "\n",
    "<p> ⬇ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
